---
title: "Data 621 Homework 5"
author: "Sung Lee"
date: "11/29/2021"
output: 
  html_document:
    code_folding: show
    df_print: paged
    smooth_scroll: false
number_sections: true
theme: paper
---

# Introduction  
In this homework assignment, you will explore, analyze and model a data set containing information on
approximately 12,000 commercially available wines. The variables are mostly related to the chemical properties of
the wine being sold. The response variable is the number of sample cases of wine that were purchased by wine
distribution companies after sampling a wine. These cases would be used to provide tasting samples to
restaurants and wine stores around the United States. The more sample cases purchased, the more likely is a
wine to be sold at a high end restaurant. A large wine manufacturer is studying the data in order to predict the
number of wine cases ordered based upon the wine characteristics. If the wine manufacturer can predict the
number of cases, then that manufacturer will be able to adjust their wine offering to maximize sales.  

Your objective is to build a count regression model to predict the number of cases of wine that will be sold
given certain properties of the wine. HINT: Sometimes, the fact that a variable is missing is actually predictive of
the target. You can only use the variables given to you (or variables that you derive from the variables provided).

# Data Exploration  

The following are the variables provided with their description.


Variable | Description
---------|-------------------------  
INDEX|Identification Variable (do not use)
TARGET|Number of Cases Purchased
AcidIndex|Proprietary method of testing total acidity of wine by using a weighted average
Alcohol|Alcohol Content
Chlorides|Chloride content of wine
CitricAcid|Citric Acid Content
Density|Density of Wine
FixedAcidity|Fixed Acidity of Wine
FreeSulfurDioxide| Sulfur Dioxide content of wine
LabelAppeal|Marketing Score indicating the appeal of label design for consumers. High numbers suggest customers like the label design. Negative numbers suggest customes don't like the design.
ResidualSugar|Residual Sugar of wine
STARS|Wine rating by a team of experts. 4 Stars = Excellent, 1 Star = Poor
Sulphates|Sulfate conten of wine
TotalSulfurDioxide|Total Sulfur Dioxide of Wine
VolatileAcidity|Volatile Acid content of wine
pH|pH of wine  


```{r, echo=FALSE, warning=FALSE}
library(mice)
library(VIM)
library(pastecs)
library(tidyverse)
# https://www.rdocumentation.org/packages/naniar/versions/0.6.1
library(naniar)
library(reshape2)
library(ggplot2)
library(readr)
library(dplyr)
# Used for skewness
library(moments)

# Log Scale
library(scales)

# Correlation corrplot
# https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html
library(corrplot)

# https://www.rdocumentation.org/packages/car/versions/3.0-11/topics/vif
library(car)

library(caret)
library(leaps)
library(pROC)
```  

 

```{r, echo=FALSE}
# To help prevent scientific notation for viewed values
options(scipen=100)

# To set the number of decimal places
options(digits=4)

# From http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}


# Reading in the csv files
# Uncomment for Github
trainData <- read_csv("https://github.com/logicalschema/Fall-2021/raw/main/DATA621/hw5/wine-training-data.csv")
# trainData <- read_csv("wine-training-data.csv")

# Uncomment for Github
evalData <- read.csv("https://github.com/logicalschema/Fall-2021/raw/main/DATA621/hw5/wine-evaluation-data.csv")
# evalData <- read.csv("wine-evaluation-data.csv")

# Remove the INDEX column
trainData <- subset(trainData, select = -c(INDEX) )
evalData <- subset(evalData, select = -c(IN) )

```  

The following is a snippet of the training data:

```{r, echo=FALSE}
head(trainData)
```

The evaluation data had a variable named `IN` which was different from the training data's `INDEX` variable.


## Summary Analysis
Here is a summary of the training data:  


```{r, echo=FALSE}
summary(trainData)
```  

The variables `ResidualSugar`, `Chlorides`, `FreeSulfurDioxide`, `TotalSulfurDioxide`, `pH`, `sulphates`, `Alcohol`, and `STARS` have missing values.


## Missing Values  
The following uses the `mice` and `VIM` packages to look for possible patterns in missing data.  

```{r, echo=FALSE}
md.pattern(trainData)
```


```{r, echo=FALSE}

aggr_plot <- aggr(trainData, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(trainData), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))


marginplot(trainData[c(1,2)])
```


## Correlation  


```{r, echo=FALSE}
# Correlations 
corrTrain = cor(trainData, use = "na.or.complete")
corrplot(corrTrain)

```


```{r, echo=FALSE}
cor(trainData[sapply(trainData, is.numeric)], use = "na.or.complete")

``` 

## Distributions 


```{r, echo=FALSE}
par(mfrow = c(3, 3))

plotData <- melt(trainData)

ggplot(plotData, aes(x= value)) + 
  theme(panel.border = element_blank(), panel.background = element_blank(), 
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  geom_density(fill='dodgerblue') + facet_wrap(~variable, scales = 'free') 

```  



# Data Preparation  

With the multiple variables with missing data, I will use the `mice()` function for imputing values. The following is a summary of a temporary data frame created using the training data with the function.

```{r, echo=FALSE}

# Function for imputing data
imputeData <- function(df){
  
  df <- mice(data = df, m = 1, method = "pmm", maxit = 10, seed = 1130)
  df <- mice::complete(df, 1)
}

trainData <- imputeData(trainData)
evalData <- imputeData(evalData)

```  

The following is a snippet of the training data along with an updated summary after imputation.  


```{r, echo=FALSE}
head(trainData)
summary(trainData)



```

## Correlation  

Here is an updated correlation after the data imputation.

```{r, echo=FALSE}
# Correlations 
corrTrain = cor(trainData, use = "na.or.complete")
corrplot(corrTrain)

```


```{r, echo=FALSE}
cor(trainData[sapply(trainData, is.numeric)], use = "na.or.complete")

``` 

## Distributions 

Here are updated distributions for the training data after imputation.

```{r, echo=FALSE}
par(mfrow = c(3, 3))

plotData <- melt(trainData)

ggplot(plotData, aes(x= value)) + 
  theme(panel.border = element_blank(), panel.background = element_blank(), 
        panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  geom_density(fill='dodgerblue') + facet_wrap(~variable, scales = 'free') 

```  



# Build Models  
Next, we will work on building models and finding the best fit to predict the number of cases sold. Before we move on, let's split the training data (80/20).

## Splitting Data  

Here are snippets of the split training data.

```{r, echo=FALSE}
set.seed(1130)
trainIndex <- createDataPartition(trainData$TARGET, p = 0.8, 
                                  list = FALSE)

training <- trainData[trainIndex, ]
evaluation <- trainData[-trainIndex, ]

head(training)
head(evaluation)
```  


## Model 1
For the first model, I will use a Poisson Regression utilizing all of the variables.


```{r, echo=FALSE}
model1 <- glm(TARGET~ .,data=training, family=poisson())

summary(model1)

```

```{r, echo=FALSE}
# Print Significant Variables from a model
sigFormula <- function(modelX) {
  toselect.x <- summary(modelX)$coeff[-1,4] < 0.05 

  # select sig. variables
  relevant.x <- names(toselect.x)[toselect.x == TRUE] 

  # formula with only sig variables
  sig.formula <- as.formula(paste("y ~",paste(relevant.x, collapse= "+")))
  
  return(sig.formula)
}

print(sigFormula(model1))

```

The significant variables in this model are `VolatileAcidity`, `Chlorides`, `FreeSulfurDioxide`, `TotalSulfurDioxide`, `pH`, `Sulphates`, `LabelAppeal`, `AcidIndex`, `STARS`.  

Let's see how this model works with the evaluation data.  

```{r, echo=FALSE}
calc_rmse <- function(actual, predicted) {
  value <- sqrt(sum((actual - predicted)^2) / length(actual))

  return(value)
}

# RMSE of first model - training dataset
model1_rmse_training <- mean(calc_rmse(training$TARGET, predict(model1, newdata = training)))

# RMSE of first model - evaluation dataset
model1_rmse_evaluation <- mean(calc_rmse(evaluation$TARGET, predict(model1, newdata = evaluation)))

model1_aic <- model1$aic

```  

The RMSE (root-mean-square error) for the training data is `r model1_rmse_training`.  
The RMSE (root-mean-square error) for the evaluation data is `r model1_rmse_evaluation`.  
The AIC for the model is `r model1_aic`.


## Model 2  

For model 2, I will use `LabelAppeal`, `STARS`, `VolatileAcidity`, `ToTalSulfurDioxide`, and `Alcohol`. For the variables `LabelAppeal` and `STARS`, I will treat them as factors instead of using their numeric form.

This is a summary of model 2.

```{r, echo=FALSE}
model2 <- glm(TARGET~ as.factor(LabelAppeal) + as.factor(STARS) + VolatileAcidity + TotalSulfurDioxide + Alcohol, data=training, family=poisson())

summary(model2)

```  

Let's see how this model works with the evaluation data.  

```{r, echo=FALSE}
# RMSE of first model - training dataset
model2_rmse_training <- mean(calc_rmse(training$TARGET, predict(model2, newdata = training)))

# RMSE of first model - evaluation dataset
model2_rmse_evaluation <- mean(calc_rmse(evaluation$TARGET, predict(model2, newdata = evaluation)))

model2_aic <- model2$aic

```  

The RMSE (root-mean-square error) for the training data is `r model2_rmse_training`.  
The RMSE (root-mean-square error) for the evaluation data is `r model2_rmse_evaluation`.  
The AIC for the model is `r model2_aic`.  


## Model 3  
This model will be a multiple linear regression model. 

```{r, echo=FALSE}
model3 <- lm(TARGET ~ ., data=training)
summary(model3)
```  

The model explains 46% of the data. 

```{r, echo=FALSE}
# RMSE of first model - training dataset
model3_rmse_training <- mean(calc_rmse(training$TARGET, predict(model3, newdata = training)))

# RMSE of first model - evaluation dataset
model3_rmse_evaluation <- mean(calc_rmse(evaluation$TARGET, predict(model3, newdata = evaluation)))

#model3_aic <- model3$aic
model3_aic <- extractAIC(model3)
```

The RMSE (root-mean-square error) for the training data is `r model3_rmse_training`.  
The RMSE (root-mean-square error) for the evaluation data is `r model3_rmse_evaluation`.  
The AIC for the model is `r model3_aic`.  

# Selecting Models  

After the construction of the models, I will select the best model and apply it to the evaluation data. Looking at the AIC and RMSE measures, model 1 is the best of the three models.

## Predictions  
Model 1 will be used on the `evalData` from the beginning of the assignment.

```{r, echo=FALSE}
predicted <- round(predict(model1, newdata = evalData),0)
evalData$TARGET <- predicted

head(evalData)


```




